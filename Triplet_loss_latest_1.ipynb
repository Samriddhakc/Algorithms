{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Lambda\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from keras.datasets import cifar10,mnist\n",
    "from keras.callbacks import ModelCheckpoint#save your model\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train_1),(x_test, y_test_1) = mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test/= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "(10000,)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "img_rows=28\n",
    "img_cols=28\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train_1 = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test_1 = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train_1 = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test_1 = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "print(x_train_1.shape)\n",
    "print(y_train_1.shape)\n",
    "print(y_test_1.shape)\n",
    "print(x_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making even splits of validation and train set \n",
    "#x_train_1=x_train[:35000]\n",
    "##y_train_1=y_train[:35000]\n",
    "#x_add=x_train[35000:]\n",
    "#y_add=y_train[35000:]\n",
    "#x_test_1=np.vstack((x_add,x_test))\n",
    "#y_test_1=np.hstack((y_add,y_test))\n",
    "#print(x_test_1.shape)\n",
    "#print(y_test_1.shape)\n",
    "#print(x_train_1.shape)\n",
    "#print(y_train_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triples_indices(grouped, n):\n",
    "    num_classes = len(grouped) \n",
    "    positive_labels = np.random.randint(0, num_classes, size=n)\n",
    "    negative_labels = (np.random.randint(1, num_classes, size=n) + positive_labels) % num_classes\n",
    "    triples_indices = []\n",
    "    for positive_label, negative_label in zip(positive_labels, negative_labels):\n",
    "        negative = np.random.choice(grouped[negative_label])\n",
    "        positive_group = grouped[positive_label]\n",
    "        m = len(positive_group)\n",
    "        anchor_j = np.random.randint(0, m)\n",
    "        anchor = positive_group[anchor_j]\n",
    "        positive_j = (np.random.randint(1, m) + anchor_j) % m\n",
    "        positive = positive_group[positive_j]\n",
    "        triples_indices.append([anchor, positive, negative])\n",
    "    return np.asarray(triples_indices)\n",
    "\n",
    "def batch_all_triplet_indices(grouped,n):\n",
    "    num_classes=len(grouped)\n",
    "    triples_indices = []\n",
    "    for i in range(n):\n",
    "        positive_index=np.random.randint(num_classes)\n",
    "        positive_labels_indices=grouped[positive_index]\n",
    "        positive=np.random.choice(positive_labels_indices)\n",
    "        anchor=np.random.choice(positive_labels_indices)\n",
    "        negative_index=np.random.randint(num_classes)\n",
    "        while (negative_index == positive_index):\n",
    "            negative_index=np.random.randint(num_classes)\n",
    "        negative = np.random.choice(grouped[negative_index])\n",
    "        triples_indices.append([anchor,positive, negative])\n",
    "    return np.asarray(triples_indices) \n",
    "\n",
    "def get_triples_data(x, grouped, n):\n",
    "    indices = batch_all_triplet_indices(grouped, n)\n",
    "    return x[indices[:,0]], x[indices[:,1]], x[indices[:,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(inputs):\n",
    "    margin=0.1\n",
    "    anchor, positive, negative = inputs\n",
    "    positive_distance = K.square(anchor - positive)\n",
    "    negative_distance = K.square(anchor - negative)\n",
    "    positive_distance = K.sqrt(K.sum(positive_distance, axis=1, keepdims=True))\n",
    "    negative_distance = K.sqrt(K.sum(negative_distance, axis=1, keepdims=True))\n",
    "    loss = positive_distance - negative_distance+margin\n",
    "    loss=K.maximum(0.0,loss)\n",
    "    return K.mean(loss)\n",
    "\n",
    "def build_model(input_shape):\n",
    "    base_input = Input(input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(base_input)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    #kernel_regularizer=regularizers.l2(0.4)\n",
    "    x = Dense(5,kernel_regularizer=regularizers.l2(0.3),activation='softmax')(x)\n",
    "    x = Lambda(lambda x: K.l2_normalize(x, axis=-1))(x) # force the embedding onto the surface of an n-sphere\n",
    "    embedding_model = Model(base_input, x, name='embedding')\n",
    "    \n",
    "    anchor_input = Input(input_shape, name='anchor_input')\n",
    "    positive_input = Input(input_shape, name='positive_input')\n",
    "    negative_input = Input(input_shape, name='negative_input')\n",
    "    \n",
    "    anchor_embedding = embedding_model(anchor_input)\n",
    "    positive_embedding = embedding_model(positive_input)\n",
    "    negative_embedding = embedding_model(negative_input)\n",
    "\n",
    "    inputs = [anchor_input, positive_input, negative_input]\n",
    "    outputs = [anchor_embedding, positive_embedding, negative_embedding]\n",
    "    triplet_model = Model(inputs, outputs)\n",
    "    triplet_model.add_loss(K.mean(triplet_loss(outputs)))\n",
    "    sgd = optimizers.Adam(lr=0.001)\n",
    "    triplet_model.compile(loss=None, optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "    return embedding_model, triplet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-22-755ad9c81d5c>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-755ad9c81d5c>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    def on_train_end(self, logs={}):\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class accuracy(keras.callbacks.Callback):\n",
    "     def on_train_begin(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_begin(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 27s 5s/step - loss: 2.8530 - val_loss: 2.4693\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.2008 - val_loss: 1.9085\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.6682 - val_loss: 1.4525\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.2442 - val_loss: 1.0922\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.9142 - val_loss: 0.8158\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.6623 - val_loss: 0.6078\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4725 - val_loss: 0.4543\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.3364 - val_loss: 0.3426\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.2365 - val_loss: 0.2647\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.1675 - val_loss: 0.2108\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1190 - val_loss: 0.1749\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0870 - val_loss: 0.1511\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0653 - val_loss: 0.1351\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0501 - val_loss: 0.1274\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0403 - val_loss: 0.1217\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0351 - val_loss: 0.1194\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0302 - val_loss: 0.1166\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0283 - val_loss: 0.1174\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0257 - val_loss: 0.1159\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0259 - val_loss: 0.1167\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0238 - val_loss: 0.1170\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0230 - val_loss: 0.1185\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0231 - val_loss: 0.1197\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0217 - val_loss: 0.1209\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0224 - val_loss: 0.1216\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0215 - val_loss: 0.1232\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0216 - val_loss: 0.1199\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0210 - val_loss: 0.1207\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0201 - val_loss: 0.1216\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0205 - val_loss: 0.1212\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0195 - val_loss: 0.1211\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0193 - val_loss: 0.1213\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0198 - val_loss: 0.1244\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0197 - val_loss: 0.1219\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0191 - val_loss: 0.1253\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0193 - val_loss: 0.1244\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0187 - val_loss: 0.1231\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0195 - val_loss: 0.1285\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0184 - val_loss: 0.1267\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0186 - val_loss: 0.1296\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0196 - val_loss: 0.1252\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0192 - val_loss: 0.1287\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0191 - val_loss: 0.1281\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0181 - val_loss: 0.1286\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0183 - val_loss: 0.1290\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0174 - val_loss: 0.1292\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0173 - val_loss: 0.1299\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0180 - val_loss: 0.1266\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0181 - val_loss: 0.1284\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0179 - val_loss: 0.1294\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0180 - val_loss: 0.1294\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0174 - val_loss: 0.1298\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0181 - val_loss: 0.1324\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0170 - val_loss: 0.1313\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0167 - val_loss: 0.1315\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0174 - val_loss: 0.1323\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0171 - val_loss: 0.1299\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0169 - val_loss: 0.1288\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0164 - val_loss: 0.1327\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0166 - val_loss: 0.1328\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0164 - val_loss: 0.1305\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0170 - val_loss: 0.1292\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0166 - val_loss: 0.1336\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0167 - val_loss: 0.1331\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0162 - val_loss: 0.1310\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0162 - val_loss: 0.1299\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.0158 - val_loss: 0.1324\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.0156 - val_loss: 0.1320\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.0161 - val_loss: 0.1323\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.0164 - val_loss: 0.1324\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.0161 - val_loss: 0.1347\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.0164 - val_loss: 0.1341\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.0159 - val_loss: 0.1348\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.0159 - val_loss: 0.1348\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.0158 - val_loss: 0.1301\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.0157 - val_loss: 0.1326\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0155 - val_loss: 0.1304\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0157 - val_loss: 0.1316\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0159 - val_loss: 0.1313\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0151 - val_loss: 0.1329\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0154 - val_loss: 0.1342\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0152 - val_loss: 0.1341\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0156 - val_loss: 0.1373\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 23s 5s/step - loss: 0.0152 - val_loss: 0.1355\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0159 - val_loss: 0.1349\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0153 - val_loss: 0.1331\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0150 - val_loss: 0.1342\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0157 - val_loss: 0.1347\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0153 - val_loss: 0.1362\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0153 - val_loss: 0.1304\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0143 - val_loss: 0.1337\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0153 - val_loss: 0.1354\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0146 - val_loss: 0.1361\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0156 - val_loss: 0.1375\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0146 - val_loss: 0.1368\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0151 - val_loss: 0.1402\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0151 - val_loss: 0.1375\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0147 - val_loss: 0.1350\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0146 - val_loss: 0.1387\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0153 - val_loss: 0.1377\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "batch_size = 2000\n",
    "steps_per_epoch = 5\n",
    "epochs = 100\n",
    "def triplet_generator(x, y, batch_size):\n",
    "    grouped = defaultdict(list)\n",
    "    for i, label in enumerate(y):\n",
    "        grouped[label].append(i)\n",
    "        \n",
    "    while True:\n",
    "        x_anchor, x_positive, x_negative = get_triples_data(x_train_1, grouped, batch_size)\n",
    "        yield ({'anchor_input': x_anchor,\n",
    "               'positive_input': x_positive,\n",
    "               'negative_input': x_negative},None)\n",
    "validation_steps=int(x_test_1.size/batch_size)\n",
    "embedding_model, triplet_model = build_model((28,28,1))\n",
    "validation_steps=int(x_test_1.size/batch_size)\n",
    "history = triplet_model.fit_generator(triplet_generator(x_train_1, y_train_1, batch_size),steps_per_epoch=steps_per_epoch,\n",
    "                                          epochs=epochs,verbose=1,validation_data=triplet_generator(x_test_1,y_test_1,batch_size),validation_steps=10,max_queue_size=1,workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.plot(history.history['loss'], label='loss') \n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vecs = np.zeros((len(x_train_1),5))\n",
    "for i,x in enumerate(x_train_1):\n",
    "    x = (x/255).astype(np.float32)\n",
    "    embedding_value= embedding_model.predict(np.expand_dims(x,axis=0))\n",
    "    emb_vecs[i]=embedding_value/np.linalg.norm(embedding_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47671002 0.47101951 0.43038431 0.43836725 0.41652337] [0.47682688 0.4709394  0.43052056 0.43807882 0.4166429 ]\n"
     ]
    }
   ],
   "source": [
    "print(emb_vecs[1],emb_vecs[400])\n",
    "def distance(emb1, emb2):\n",
    "    return np.sqrt(np.sum(np.square(emb1- emb2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def k_nearest_neighbor(embedding_values,labels,test_value,k): \n",
    "    '''calculates the k nearest neighbor a a given test_value and a particular k'''\n",
    "    similar=np.zeros(len(embedding_values))\n",
    "    for i,emb_vec in enumerate(embedding_values):\n",
    "        similar[i] = distance(test_value,emb_vec)\n",
    "    arrangement= np.argsort(similar)\n",
    "    arrangement=arrangement[:k]\n",
    "    k_nearest=labels[arrangement]\n",
    "    correct_index_list=stats.mode(k_nearest)\n",
    "    correct_index=correct_index_list[0].tolist()\n",
    "    return correct_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "test_image=x_train_1[101]\n",
    "test_image=embedding_model.predict(np.expand_dims(test_image,axis=0))\n",
    "correct_index=k_nearest_neighbor(emb_vecs,y_train_1,test_image,5)\n",
    "print(correct_index)\n",
    "print(y_train_1[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "score=0\n",
    "count=0\n",
    "for i,x in enumerate(emb_vecs):\n",
    "    pred=k_nearest_neighbor(emb_vecs,y_train_1,x,5)\n",
    "    if (pred==y_train_1[i]):\n",
    "        score=score+1\n",
    "    if (count==20):\n",
    "        break \n",
    "    count=count+1\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=triplet_model.evaluate(triplet_generator(x_test_1,y_test_1,batch_size),steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=triplet_model.predict_generator(triplet_generator(x_test_1,y_test_1,batch_size),steps=100,workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_image=x_train_1[4]\n",
    "test_image=embedding_model.predict(np.expand_dims(test_image,axis=0))\n",
    "correct_index=k_nearest_neighbor(emb_vecs,y_train_1,test_image,5)\n",
    "print(correct_index)\n",
    "print(y_train_1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Desktop/logdir/model.ckpt'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir=\"./Desktop/logdir\"\n",
    "tf.reset_default_graph()\n",
    "session=tf.Session()\n",
    "embedding_var=tf.Variable(emb_vecs,name='mnist_embedding')\n",
    "saver=tf.train.Saver()\n",
    "session.run(tf.global_variables_initializer())\n",
    "saver.save(session,os.path.join(logdir,\"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_meta_file(savedir, labels):\n",
    "    with open(savedir+\"/metadata.tsv\", \"w\") as metafile:\n",
    "        string_array = []\n",
    "        for label in labels:\n",
    "            string_array.append(str(label)+\"\\n\")\n",
    "        metafile.writelines(string_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_meta_file(logdir,y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
